\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{graphicx}
% \usepackage{fullpage}

%opening
\title{Relazioni dal laboratorio di calcolo}
\author{Riccardo Iaconelli}

\begin{document}

\maketitle

\begin{abstract}
Durante il Laboratorio di calcolo del terzo anno vengono mostrate alcune tecniche numeriche per la soluzione di problemi comuni in Fisica. In particolare l'attenzione è posta su diverse tecniche per svolgere integrali, sia di tipo deterministico che Monte-Carlo. Il programma si divide in più parti: per cominciare una sezione in cui si investigano tecniche per ridurre l'imprecisione numerica implicita di un calcolatore, dopodiché si studiano imprecisioni e rapidità di diversi algoritmi per il calcolo di integrali, e infine si applicano queste tecniche a problemi fisici. Come ultimo esercizio si implementa il metodo di Runge-Kutta per risolvere numericamente equazioni differenziali.
\end{abstract}
\clearpage

\section{Serie numeriche e precisione floating point}
Questo primo esercizio viene eseguito per mostrare come si possono ridurre eventuali errori di calcolo introdotti dalle normali operazioni aritmetiche.

\subsection{Analisi teorica}
All'interno del calcolatore le cifre non sono rappresentabili con precisione infinita. A causa di ciò, con ogni operazione effettuata è possibile ottenere errori numerici dovuti a due tipi di problemi.
\begin{description}
 \item[Errore di overflow (o underflow)] Questo errore avviene quando il risultato è più grande del massimo numero rappresentabile, o più piccolo del minimo numero rappresentabile.
 \item[Errore di troncamento] Quando operazioni di \textit{shift} comportano errori di arrotondamento.
\end{description}

Per vedere come questo è possibile, studiamo come sono rappresentati i numeri all'interno di un calcolatore.
La rappresentazione all'interno del calcolatore dei numeri floating-point è fissata dallo standard IEEE 754 (1985).
Questa specifica indica che, dato $x$ numero float, viene separato in tre parti (\textit{segno}, \textit{mantissa} ed \textit{esponente}) nel seguente modo:
\begin{equation}
 x= (-1)^\text{\ segno} \cdot\text{mantissa}\cdot 2^{\text{\ esponente}-E}
\end{equation}

Per ottimizzare le oeprazioni, gni numero viene inoltre memorizzato in forma ``normalizzata'', ovvero si ha sempre che
$$\text{mantissa} = 1.\text{frazione}$$
Ad esempio, il numero:
$$0.15625_{10} = 0.00101_2 = 1.01_2 \cdot 2^{-3}$$

In particolare, lo standard definisce due tipi di numeri con differenti precisione e con diverso \textit{bias} ($E$):
\begin{description}
 \item[\texttt{float}] Numeri in singola precisione, che utilizzano 32 bit di memoria. $E = 127$.
 \item[\texttt{double}] Numeri in doppia precisione, che utilizzano 64 bit di memoria. In questo caso, $E=1023$.
\end{description}
I bit utilizzati per la rappresentazione sono così ripartiti:
\begin{center}
\begin{tabular}[center]{c|c|c|c}
 & Segno & Esponente & Frazione \\ 
\hline
float & 1 & 8 & 23\\
\hline
double & 1 & 11 & 52 \\
\end{tabular}
\end{center}

Nel caso appena visto, $0.15625_{10} = 1.01_2 \cdot 2^{-3}$ sarebbe rappresentato in questo modo in un \texttt{float}:
\begin{itemize}
\item $\text{segno}=0$
\item $\text{esponente}=127-3=124=11111000$
\item $\text{frazione}=010000...$
\end{itemize}
Una rappresentazione grafica della memoria utilizzata da un numero \texttt{double} è qui offerta:

% \begin{figure}
%  \centering
\begin{center}
 \includegraphics[scale=0.35]{./images/1000px-IEEE_754_Double_Floating_Point_Format.png}
\end{center}
 % 1000px-IEEE_754_Double_Floating_Point_Format.svg.png: 1000x202 pixel, 72dpi, 35.28x7.13 cm, bb=0 0 1000 202
%  \caption{Una rappresentazione grafica di un numero float}
% \end{figure}
Si nota facilmente che c'è un errore intrinseco nella rappresentazione dei numeri dovuto alla finitezza della memoria utilizzata, non tutti i numeri sono infatti rappresentabili, e il ``gap'' tra un numero e il successivo varia in base all'ordine di grandezza utilizzato. Questo errore aumenta con alcune operazioni, consideriamo ad esempio una somma.

\subsubsection{L'algoritmo di somma}
Quando un calcolatore deve eseguire una somma, procede nel seguente modo:
\begin{itemize}
\item Per prima cosa, vengono confrontati gli esponenti dei due numeri, e viene \emph{shiftato}\footnote{traslato, l'operazione equivalente a dividere o moltiplicare per due} l'esponente del numero più piccolo, fino a che i due esponenti non sono uguali.
\item Vengono a questo punto sommate direttamente le mantisse, seguendo le normali regole del complemento a due.
\item Il numero così ottenuto viene normalizzato, modificando l'esponente di conseguenza
\item Come ultimo passaggio, la mantissa viene arrotondata per rimanere nel numero di bit richiesto. 
\end{itemize}

Da questo processo si vede chiaramente come si ha una grossa perdita di precisione nel caso di somme di numeri di ordini di grandezza molto diversi tra loro. Quando infatti la differenza tra gli esponenti è dell'ordine di grandezza della precisione della mantissa, il contributo del numero più piccolo si perde nell'arrotondamento.
9zpf6mkofteny953w
Questo concetto sarà ulteriormente chiarito nel prossimo esercizio.

\subsubsection{La serie di Eulero}
Per mettere in pratica quanto visto finora in teoria, studiamo le somme parziali della serie di Eulero:
$$\sum_{n=1}^\infty \frac{1}{n^2} = \frac{\pi^6}{2} \simeq 1.6449340 $$

Per mettere più in evidenza il problema di arrotondamento, eseguiamo i nostri calcoli utilizzando solamente variabili di tipo \texttt{float}. Notiamo che nell'ordine di grandezza in cui stiamo lavorando ($2^0$) il più piccolo step rappresentabile è dato direttamente dalla precisione della mantissa: $2^{-23}\simeq 1.19\cdot10^{-7}$. Tutti i risultati saranno dunque presentati con sole 7 cifre significative.

\paragraph{Somma crescente}
Proviamo inizialmente a sommare i numeri in ordine crescente, ovvero consideriamo
$$S_k := \sum_{n=1}^k \frac{1}{n^2}$$
Notiamo immediatamente che quando $n^2\simeq2^{24}$, l'operazione di arrotondamento successiva alla somma (potendo utilizzare solo 23 bit per la mantissa, e sommando sempre un numero di ordine di grandezza $2^0$) perda ogni tipo di contributo dei nuovi numeri.

Ci aspettiamo allora che, definito: $$k_\text{critico} := \sqrt{2^{24}} = 4096$$


$\forall k \geq k_\text{critico}$ la somma smetta di crescere, e dunque $S_k = S_{k+1} = ...$.

\paragraph{Somma decrescente}
Per evitare il problema di arrotondamento appena illustrato, possiamo provare a considerare una somma ``inversa'' o decrescente, ovvero definire (con un piccolo abuso di linguaggio):

$$S_k := \sum_{n=k}^1 \frac{1}{n^2}$$

In questo modo, la somma parziale mantiene il più possibile l'ordine di grandezza del nuovo termine da aggiungere, minimizzando il problema di arrotondamento.

\paragraph{Confronto tra i due metodi}
Dopo aver realizzato in C++ due programmi che implementassero quanto appena descritto, rappresentiamo in un grafico (in scala logaritmica) l'errore che si commette con entrambi i metodi e la differenza dal valore vero.
\begin{center}
\includegraphics[scale=.55]{../images/serie.png}
\end{center}

Notiamo come l'errore scende drammaticamente utilizzando il metodo della somma decrescente. In particolare, si raggiunge tranquillamente una precisione dell'ordine di $10^{-7}$, come prescriverebbe la teoria. Continunando con le iterazioni si arriva anche a $10^{-8}$, anche se è solo una fluttuazione numerica priva di ogni significatività.

\subsection{Conclusioni}
Abbiamo studiato come la rappresentazione finita dei numeri all'interno di un calcolatore introduca errori ed imprecisioni all'interno dei nostri algoritmi.
Questi errori, se non considerati, possono portare a significativi errori nel computo finale.

Conoscendo bene come funzionano le operazioni di base nel calcolatore, è però possibile con alcuni accorgimenti raggiungere precisioni molto vicine a quelle consentite dalla rappresentazione stessa.

Viene allegato il codice sorgente C++ che implementa gli algoritmi qui descritti.

\section{Integrazione con metodi deterministici}
Esistono diversi modi per approssimare numericamente integrali con metodi deterministici. Ci interessa trovare delle soluzioni generali, nell'ipotesi monodimensionale. Studieremo le formule di \emph{Newton-Cotes} al primo e al secondo ordine (metodo \emph{dei trapezi} e metodo \emph{di Simpson}), ed arriveremo ad implementare il metodo delle \emph{quadrature gaussiane}.

\subsection{Introduzione al problema}
L'integrazione numerica attraverso metodi deterministici presuppone che la funzione da integrare non sia necessariamente nota globalmente in forma analitica, ma ne siano perlomeno noti alcuni punti, che chiameremo \emph{campioni}.

Indicheremo i campioni della funzione (da qui in avanti $f(x)$) con la notazione $x_i$. Interpoleremo i campioni con delle funzione note dette \emph{interpolatrici} e calcoleremo l'integrale di queste ultime.

È in teoria possibile scegliere ogni tipo di funzione interpolante. Per la nostra analisi sceglieremo dei polinomi di grado generico $n$, e ne scriveremo esplicitamente le soluzioni in alcuni casi. Ovviamente, la complessità (e la precisione) di questi calcoli dipendono strettamente dal tipo di funzione scelta.

\subsection{Il polinomio interpolatore di Lagrange}
Supponiamo dunque di avere una funzione $f(x)$ e $N$ campioni $x_i = x_1, \dots, x_N$ per i quali siano noti i valori della funzione $f(x_i)$

Si consideri il \emph{polinomio di Lagrange}:
$$l_j(x):=\displaystyle\prod_{i=0;\, i\neq j}^n \dfrac{(x-x_i)}{(x_j-x_i)}$$
Notiamo che per il polinomio di Lagrange vale la seguente proprietà secondo cui
$$l_j(x) = \delta_{ij}$$
Si definisce ora il polinomio interpolatore di Lagrange come combinazione lineare dei polinomi di Lagrange:
$$P(x):= \sum_{i=0}^{n}f(x_i)\,l_i(x)$$
Notiamo che il polinomio così definito è di grado $N-1$, e inoltre $P(x_i) = f(x_i)$. Possiamo dire che $P(x)$ \emph{interpola} esattamente la funzione $f(x)$ nei punti $x_i$.

\subsection{Le formule di Newton-Cotes}
Utilizziamo il polinomio interpolatore di Lagrange per derivare delle formule utili al calcolo degli integrali. Le formule che stiamo per introdurre si chiamano di Newton-Cotes, e possono essere applicate nell'ipotesi che gli $x_i$ siano equispaziati.
Nel caso invece fosse possibile campionare la funzione in più punti, è possibile fare ricorso a strumenti più potenti come le formule di \emph{quadratura gaussiana}, che vedremo in seguito.

Partiamo dalla definizione di integrale secondo Riemann:
$$\int f(x)dx = \lim_{\Delta x \to 0} \sum f(x)\Delta x$$
Supponiamo di volere integrare la funzione $f(x)$ nell'intervallo $[a,b]$
Allora, scelti appositamente dei pesi $\omega_i$, possiamo approssimare il nostro integrale con una somma:
$$\int_a^bf(x)dx \simeq \sum_i \omega_i f(x_i)$$

A questo punto:
$$\int_a^bf(x)dx \simeq \int_a^b P(x) dx = \sum_i \omega_i f(x_i)$$
dove
$$\omega_i := \int_a^b l_i(x) dx $$

Utilizziamo ora l'ipotesi di equispaziatura dei campioni. In questo caso, con $h:=(b-a)/N$, si ha necessariamente $x_i = a+hi$. Operiamo il cambio di variabile
$$z:=\frac{x-a}{h}$$
Si dunque ha che
$$\omega_i = h\int_0^n l_i(a+zh)dz = h\int_0^n \prod_{i\neq j}\frac{z-i}{j-i}dz$$
indipendente dagli estremi di integrazione a e b.

Definiamo per comodità anche i parametri $$\gamma_j := \frac{\omega_j}{h} = \int_0^n \prod_{i\neq j}\frac{z-i}{j-i}dz$$.

Dobbiamo però arrivare anche alla stima dell'errore che commettiamo.
Si può provare con il teorema di Rolle che, dati $n$ punti, commettiamo un errore dato da:
$$f(x)-P(x) = \frac{1}{(n+1)!}f^{(n+1)}\left(\xi(x)\right)\prod_{i=0}^{n}(x-x_i) =: \text{Err}(x)$$
dove $\xi(x)\in[a,b]$.
A questo punto:
$$\int_a^bf(x)dx - \int_a^b P(x) dx = \int_a^b \text{Err}(x)dx$$

\subsection{Metodo dei Trapezi}
Il metodo dei trapezi è il metodo che si ottiene utilizzando le formule di Newton-Cotes con $n=1$. In questo caso necessariamente $x_0 = a$ e $x_1 = b$.

Un breve calcolo sui coefficienti mostra che:
$\gamma_0$ e $\gamma_1$ mostra che $$\gamma_0 = \dfrac{1}{2}\qquad \text{e}\qquad \gamma_1 = \dfrac{1}{2}$$

Stimiamo anche $\int_a^b \text{Err}(x)dx$.
Per il teorema della media sappiamo che
\begin{eqnarray}
\int_a^b\text{Err}(x)dx =& \dfrac{1}{2}\displaystyle\int_a^bf''(\xi(x))(x-a)(x-b)\,dx \\
=& \dfrac{1}{2}f''(c)\displaystyle\int_a^b(x-a)(x-b)\,dx \\
=& \dfrac{h^3}{2}f''(c)\displaystyle\int_0^1z(z-1)\,dz \\
=& -\dfrac{h^3}{12}f''(c) \\ \leq& \text{max}(f''(x))\dfrac{h^3}{12}
\end{eqnarray}

Dunque in generale, al variare dell'intervallo, l'errore scalerà come $h^3$.

\subsection{Metodo di Simpson}
Il metodo di Simpson è quello che si ottiene dalle formule di Newton-Cotes al secondo ordine.
In questo caso si calcola semplicemente:
$$\gamma_0 = \dfrac{1}{3}\qquad \gamma_1 = \dfrac{4}{3}\qquad \text{e}\qquad \gamma_2 = \dfrac{1}{3}$$

Dunque il nostro integrale sarà dato da
$$\int_a^bf(x)dx = \frac{h}{3} \big[f(x_0)+4f(x_1)+f(x_2)\big] + E_2$$
Analogamente a prima, calcoliamo il nostro errore. Notiamo che aggiungendo al campionamento un punto coincidente a quello centrale ($x_3=x_1 = \frac{a+b}{2}$) non vengono dati contributi alla stima dell'integrale, ma possiamo valutare l'errore (più semplice) $E_3$ delle formule di ordine 3.

Utilizzando sempre il teorema della media pesata:
$$E_3=\frac{h^5}{24}\,\text{max}(f^{(4)})\int_0^2z(z-1)^(z-2)\,dz\, = \text{max}(f^{(4)})\frac{h^5}{90}$$

\subsection{Metodo delle Quadrature Gaussiane}
Fino a questo momento, abbiamo ristretto la nostra analisi a funzioni campionate ad intervalli regolari. Nel caso in cui possiamo fare cadere questa ipotesi e scegliere noi i punti nei quali campionare la funzione, riusciamo ad avere stime estremamente più efficienti. Un metodo per fare ciò è il cosiddetto metodo delle \emph{quadrature gaussiane}.

Il teorema fondamentale su cui si basa questo metodo dice che, dato $P(x)$ generico polinomio di grado minore di $2N$, e date $x_0,\dots,x_{n-1}$ radici di un polinomio ortogonale di ordine $N$, vale la seguente uguaglianza
$$\int_a^b P(x)\,\omega(x)\,dx = \sum_{i=0}^{n-1} \omega_i P(x_i)$$
o equivalentemente
$$\int_a^b f(x)\,\omega(x)\,dx = \sum_{i=0}^{n-1} \omega_i P(x_i)$$
è esatta fino all'ordine $2N-1$, dove $\omega(x)$ è la misura e gli $\omega_i$ sono definiti come prima.

In altre parole, il succo di questo teorema sta nel fatto che scegliendo i campioni proprio nelle radici di una famiglia di polinomi ortogonali, riusciamo a utilizzare la stima dell'errore di Newton-Cotes di ordine doppio rispetto a quanto avremmo con un campionamento uniforme, ovvero, con $P_n$ polinomio ortogonale di ordine $n$:

$$\int_a^b f(x)\,\omega(x)dx = \sum_{i=0}^{n-1}\omega_i\,f(x_i) + \frac{1}{(2n)!}\int_b^a f^{(2n)}\left(\xi(x)\right)P_n^2(x)\omega(x)\,dx$$

\subsection{I metodi alla prova}
Testiamo i metodi di integrazione con una funzione particolarmente ostica:
$$f(x) = (e^x+1+x^9-8x^8+\sinh(5x))e^{-x^2}$$
Mostriamo qui il grafico e il grafico logaritmico della funzione:
%\begin{figure}[htp]
%\centering
\begin{center}
\includegraphics[scale=0.5]{../images/funzione-integranda.png}
\end{center}
\begin{center}
\includegraphics[scale=0.5]{../images/funzione-integranda-log.png}
\end{center}
%\caption{Funzione integranda}
%\end{figure}
Come test delle procedure, integriamo questa funzione tra 1 e 10, e valutiamo il modulo dell'errore rispetto al valore vero dell'integrale (ottenuto mediante procedure di integrazione indipendenti e a precisione arbitraria).

\subsubsection{Errore in funzione del numero di intervalli}
Per aumentare la precisione dei nostri conti senza fare crescere i polinomi utilizzati di grado, possiamo dividere il nostro intervallo di integrazione in $m$ sottointervalli ($m = (b-a)/h$).

Calcolando esplicitamente l'errore in funzione di $m$, si ottengono i seguenti risultati:
\begin{description}
\item[Trapezi] $$\text{Err} \propto \frac{(b-a)^3}{12m^2}\propto\frac{1}{m^2}$$
\item[Simpson] $$\text{Err} \propto \frac{(b-a)^5}{180(2m)^4} \propto\frac{1}{m^4}$$
\item[Quadrature gaussiane] Utilizzando un polinomio di ordine $n$ si ha che $$\text{Err} \propto m\frac{f^{(2n)}(\xi)}{(2n)!}\frac{1}{m^{2n}} \propto\frac{1}{m^{2n-1}}$$
\end{description}

Dapprima svolgiamo il conto con i numeri \texttt{double} e grafichiamo l'andamento dell'errore rispetto al campionamento. Utilizziamo per le quadrature gaussiane polinomi di grado 5.
\begin{center}
\includegraphics[scale=0.5]{../images/integrali/integralisommaprecisa.png}
\end{center}
Notiamo come la precisione del metodo delle quadrature gaussiane raggiunge quasi subito la precisione macchina, mentre gli altri due metodi impiegano più tempo a convergere.

Utilizziamo, per continuare la nostra analisi, una libreria C (GNU MPFR) per utilizzare dei numeri floating-point a 50 cifre significative, e ripetiamo i risultati con più intervalli.

\begin{center}
\includegraphics[scale=0.5]{../images/integrali/integralibigprecision-longrun.png}
\end{center}

Notiamo come l'errore sia nel metodo dei trapezi che in quello di Simpson continua a calare come previsto fino a una precisione di $10^{-20}$, oltre la quale entrano in gioco arrotondamenti sconosciuti che limitano la velocità di caduta dell'errore delle quadrature gaussiane.

Eseguendo un fit con una funzione del tipo $y = Ax^{-B}$ per valutare la pendenza delle rette otteniamo i valori:
\begin{description}
\item[Trapezi] $B=2.13 \pm 0.43$
\item[Simpson] $B=4.14 \pm 0.11$
\item[Gauss] $B=8.9 \pm 0.5$
\end{description}

ovvero tutti valori compatibili con la teoria.

\subsection{Conclusioni}

Esistono diversi metodi deterministici per approssimare numericamente integrali analiticamente sconosciuti. Le formule di Newton-Cotes sono strumenti molto potenti nel caso in cui si disponga di campionamenti della funzione equispaziati (caso molto comune in fisica sperimentale). Nel caso, invece, in cui si possa campionare la funzione integranda a piacere, è più conveniente utilizzare le formule di quadratura gaussiana, che arrivano a soluzioni precise molto velocemente.

I risultati ottenuti sono compatibili con le previsioni teoriche.

\section{Integrazione Montecarlo}

I metodi per l'integrazione deterministica sono molto efficienti, ma risentono di problemi quando si vogliano adattare a casi multidimensionali.
Un'analisi approfondita degli errori nel caso multidimensionale mostra che la complessità computazionale cresce esponenzialmente con il numero delle dimensioni. Se prima il costo computazionale $N_c$ era proporzionale al numero di intervalli $m$, ora $N_c \propto m^d$, dove $d$ è il numero di dimensioni. Questo ha effetti catastrofici sulla convergenza degli integrali. Ad esempio, nel caso dei trapezi, l'errore diventa:
$$E\propto\frac{1}{N^{\frac{2}{d}}}$$
Ciò è particolarmente problematico per integrali in $10^9$ dimensioni, non rari in Fisica Teorica.

Per ovviare a questo fatto, vengono introdotti i metodi di integrazione Montecarlo, che basano la loro efficacia sul campionamento casuale della funzione. Questi metodi hanno la piacevole caratteristica (derivante da teoremi statistici) di avere un errore sempre proporzionale a $N^{-1/2}$ (con $N$ numero di campionamenti), indipendentemente dal numero di dimensioni in cui si sta operando.

Il teorema su cui si basa la teoria dell'integrazione Monte-Carlo è il teorema del limite centrale, che stabilisce che, date $N$ variabili aleatorie $\{x_i\}$ con distribuzione di probabilità qualsiasi, al limite $N\to\infty$ la variabile somma $y = \sum x_i$ sarà distribuita in modo gaussiano.

Supponiamo di volere calcolare l'integrale tra 0 e 1 di una generica funzione $f(x)$. Avendo a disposizione un generatore di numeri casuali a probabilità piatta, ed estraendo le $x_i$ da questo generatore, il mio integrale sarà proprio il valor medio della variabile ottenuta dalle $x_i$ e definita come $y=f(x)$.
In simboli:
$$I:=\int_0^1 f(x) dx \simeq \frac{1}{N} \sum_{i=1}^{N} f(x_i) =: \bar{I}$$

L'errore su questo integrale discende direttamente dalla sua natura statistica. Non possiamo più a questo punto parlare di maggiorante dell'errore ma soltanto di deviazioni standard rispetto alla media, utilizzando l'ipotesi che $y$ sia distribuito in maniera normale. In particolare l'errore su $\bar{I}$ sarà dato da:
$$\sigma^2_{\bar{I}} = \frac{\sigma^2_x}{\sqrt{N}} = \frac{1}{N}\left(\frac{1}{N}\sum_{i=1}^N (f(x_i)-\bar{I})^2\right)$$

\subsubsection{Campionamento di importanza}
È possibile migliorare ulteriormente la precisione del metodo Montecarlo utilizzando il cosiddetto \textit{campionamento di importanza}. Questo metodo consiste nel trovare una funzione che bene approssimi il modulo della funzione $f(x)$ in modo da campionare più frequentemente i punti che danno maggiore contributo all'integrale.

Supponiamo di avere questa funzione $g(x)$, che dovrà essere una distribuzione di probabilità negli estremi di integrazione. A questo punto, l'ovvia identità
$$\int_0^1f(x)dx = \int_0^1\frac{f(x)}{g(x)} g(x)dx$$
può essere altrimenti interpretata come il calcolo dell'integrale della funzione $$\frac{f(x)}{g(x)}$$ dove le $x_i$ sono state estratte con d.d.p. $g(x)$. Se $g(x)$ è ben scelta, il calcolo della varianza può essere estremamente ridotto, infatti:
$$\sigma^2 = \frac{1}{N} \int_0^1 (\frac{f(x)}{g(x)}-I)^2 g(x)\,dx$$
che ad esempio nel caso accademico in cui $g(x):=I\cdot f(x)$ diventa addirittura zero.

\subsection{Integrazione di una funzione con il metodo Montecarlo}
Proviamo ad integrare tramite metodo montecarlo la funzione di prima:
$$f(x) = (e^x+1+x^9-8x^8+\sinh(5x))e^{-x^2}$$

Essendo questa una funzione molto ostica per un metodo montecarlo (in quanto gli ordini di grandezza che la funzione assume nell'intervallo di integrazione sono molto diversi), ed essendo il metodo montecarlo computazionalmente molto costoso, rappresentiamo in grafico due valori:
\begin{itemize}
 \item Il valore di una singola integrazione, fissato il numero di campionamenti desiderati
 \item Una media del valore calcolato su 30 integrazioni, e una stima dell'incertezza calcolata come deviazione standard gaussiana rispetto alle trenta integrazioni.
\end{itemize}

\includegraphics[scale=.5]{../images/montecarlo-comparison.png}

È interessante notare come tutti i valori delle integrazioni singole rientrino comunque entro l'incertezza calcolata a posteriori.

Un fit con la funzione $$y=\frac{A}{N^B}$$ mostra che l'errore scende con esponente $B\simeq 0.43\pm 0.02$, sufficientemente vicino al valore teorico di $0.5$.

\subsection{Ago di Buffon}
Una nota applicazione di tecniche di integrazione Montecarlo è il cosiddetto \emph{ago di Buffon}. Questa tecnica è in realtà la simulazione a calcolatore di un metodo fisico per il calcolo del pi greco.

Si considerino un ago lungo $L$ ($<1$) e un listello di lunghezza unitaria. Il metodo per calcolare il valore di $\pi$ consiste nel contare il numero di volte in cui l'ago tocca il bordo del listello rispetto al numero totale di lanci.

Chiamando $x$ l'angolo che l'ago forma con il bordo del listello, e $y$ la distanza verticale dal bordo inferiore, è chiaro che l'ago tocca il listello quando vale una delle due condizioni:
$$y < \frac{L}{2}\sin(x) \quad\vee\quad y > 1-\frac{L}{2}\sin(x) $$
Definiamo ora una funzione ``indicatrice'' $f(x, y)$ che valga 1 quando la condizione appena enunciata è verificata e 0 altrimenti. Il suo integrale è legato al valore di $\pi$ dalla seguente relazione:
$$I=\frac{2L}{\pi}$$
$$\sigma^2 = \frac{2L}{\pi} (1 - \frac{2L}{\pi})$$
Notiamo che sia $x$ che $y$ sono estratte con distribuzione piatta tra $[0, \pi]$ e $[0,1]$.

Variamo la lunghezza dell'ago e verifichiamo che la teoria venga effettivamente rispettata.

\includegraphics[scale=.5]{../images/buffon.png}

\section{Integali di cammino}
\subsection{Le catene di Markov}

Le catene di Markov sono un meccanismo per ottenere variabli casuali con distribuzioni di probabilità arbitrarie.

Una catena di Markov è una serie di estrazioni caratterizzata dal fatto che ogni estrazione successiva alla prima dipende solamente dallo stato precedente del sistema.

Dato $E_k = (x_{1_k}, \dots, x_{n_k})$ stato del sistema nello spazio delle fasi, definiamo:
\begin{itemize}
 \item $P_{jk}$ come la probabilità di estrarre lo stato $E_k$ a partire dallo stato $E_j$.
 \item $a_k$ come la probabilità di ottenere lo stato $E_k$ alla prima estrazione.
\end{itemize}

Denotiamo inoltre con $f^{(n)}_{jk}$ la probabilità del sistema di passare dallo stato $j$ allo stato $k$ in $n$ passi.

La catena di Markov è completamente determinata se si conosce $P_{jk}$ per ogni $j$ e per ogni $k$. Possiamo allora pensare di descrivere le transizioni della catena di Markov attraverso una matrice, detta anche \emph{matrice stocastica}. Notiamo come questa matrice abbia alcune ovvie proprietà, che derivano dal fatto che $P_{jk}$ è una probabilità:
$$1\geq P_{jk} \geq 0\qquad \forall j \forall k$$
$$\sum_k Pjk = 1$$

Introduciamo ora il concetto di catena \emph{irriducibile}, che sarà il tipo di catena che ci interesserà. Cominciamo con dire che una catena di Markov può avere al suo interno insiemi di stati chiusi, ovvero un insieme di stati per cui non è possibile raggiungere alcuno stato al di fuori di esso. In simboli, detto $A$ l'insieme di stati chiuso, ed essendo $E_k\in A$, deve valere:
$$P_{kl} = 0 \quad\text{se}\quad l\not\in A$$

Una catena di Markov si dice irriducibile se tutti e soli i suoi stati formano un sistema chiuso.

Definiamo $f_{jk}^{(n)}$ come la probabilità di passare da $E_j$ a $E_k$ per la prima volta dopo $n$ iterazioni.
La probabilità di ottenere lo stato $E_k$ dallo stato $E_j$ una volta dopo un numero qualunque di passi è allora ovviamente calcolabile come:
$$f_{jk} = \sum_{n=1}^\infty f_{jk}^{(n)} $$
e definiamo anche il tempo medio per ritornare nello stato $E_j$ come
$$\mu_j = \sum_{n=1}^\infty n f_{jj}^{(n)}$$

Terminiamo le nostre definizioni con alcune classificazioni per gli stati. Uno stato $E_j$ si dice \emph{persistente} se vale $f_{jj}=1$ e \emph{transiente} se $f_{jj}<1$. Se $E_j$ è persistente, viene detto \emph{nullo} se il tempo medio per ritornare $\mu_j = +\infty$, ed \emph{ergodico} altrimenti.

Uno stato \emph{ergodico} è dunque uno stato persistente, non nullo e a-periodico.

Gli stati ergodici sono gli unici che ci interessano, nel senso spiegato dal seguente teorema:
\begin{itemize}
 \item Sia $E_j$ uno stato di una catena di Markov. $E_j$ è \emph{transiente} se e solo se:
 $$\sum_{n=0}^{+\infty} P^{(n)}_{ij} < +\infty\qquad \forall i$$
 
 \item Sia $E_j$ uno stato di una catena di Markov. $E_j$ è \emph{persistente} e \emph{nullo} se e solo se:
 $$\sum_{n=0}^{+\infty} P^{(n)}_{jj} = +\infty $$
 $$\lim_{n\to+\infty} P^{(n)}_{ij} = 0 \qquad \forall i$$
 
 \item Sia $E_j$ uno stato di una catena di Markov. $E_j$ è \emph{ergodico} se e solo se:
 $$\sum_{n=0}^{+\infty} P^{(n)}_{ij} = \frac{f_{ij}}{\mu_j} \qquad \forall i$$
 
\end{itemize}

Si capisce ora perché siano gli stati ergodici ad interessarci. Gli stati ergodici sono infatti gli unici per i quali esiste finito un limite per $P_{jk}$ che sia indipendente dallo stato iniziale, e dunque sono quelli che ci permettono di costruire una distribuzione di probabilità ben definita.

\subsection{L'algoritmo di Metropolis}
Con l'algoritmo Metropolis si possono generare facilmente catene di Markov. Il metodo non è il più efficiente possibile, ma è un metodo sufficientemente comodo per la nostra applicazione.

La creazione della catena si basa sulla generazione casuale di stati, che vengono iterativamente accettati o rigettati fino ad ottenere la distribuzione di probabilità cercata.

Supponiamo di avere un problema fisico per il quale si ha bisogno di una distribuzione di probabilità $R$. Dunque, data una catena di Markov in un generico stato $E_j$, creiamo uno stato di prova $E_{j+1}$ a partire dal precedente in un modo casuale qualunque (ad esempio, $x^i_{(j+1)}:=x^i_j+R$ con $R$ casuale tra -1 e 1).
Il nuovo stato $E_{j+1}$ sarà accettato con probabilità $$P = \max(1, R_{j+1}/R_j)$$ dove $R_i = R(E_i)$. Iterando questo procedimento si ottiene la distribuzione di probabilità voluta.

\subsection{La propagazione degli errori automatizzata}
Una volta ottenuta la distribuzione cercata, e isolati degli osservabili $a_i$, è spesso necessario valutare alcune funzioni $f(a_i)$ degli osservabili stessi. Questo può essere problematico nel momento in cui cerchiamo di propagare l'errore statistico dell'osservabile, specialmente nel caso la formulazione analitica delle derivate di $f$ non sia banale.

Per ovviare a questo ostacolo, si utilizza un metodo matematico chiamato \emph{metodo di Jacknife}.
Questo metodo consiste fondamentalmente in un cambio di variabili. Dati $a_1,\dots,a_N$ degli osservabili di valor medio $\bar{a}$, definiamo
$$a^k := \frac{1}{N-1}\sum_{i=1}^N(a_i-a_k) = \bar{a}-\frac{a_k-\bar{a}}{N-1}$$

Queste nuove variabili $a^k$ hanno due interessanti proprietà. Innanzitutto hanno stessa media e stessa varianza delle variabili di partenza:
$$\left<a^k\right> = \bar{a} $$
$$\text{Var}(\left<a^k\right>) = \text{Var}(\bar{a}) $$
e se definiamo
$$f^k:=f(a^k)$$
non solo il valor medio della funzione viene conservato
$$\left<f^k\right> = \bar{f}$$
ma anche il calcolo della varianza diventa banale
$$\text{Var}(\bar{f}) = \frac{N-1}{N} \sum_k (f^k-\bar{f})^2 = \text{Var}(\left<f^k\right>)$$
dunque evitando il calcolo delle derivate. Infatti se non avessimo effettuato il cambio di variabile:
$$\text{Var}(\bar{f}) = \text{Var}(\bar{a})\left(\frac{\partial f}{\partial a}\right)^2 $$

\subsection{Oscillatore armonico}
Utilizziamo la teoria descritta fin qui per calcolare i livelli energetici di un oscillatore armonico con gli integrali di cammino di Feynman. Poniamo per semplicità $m, \hbar$ e $\omega$ pari a 1.
Siano $i_1$ e $i_2$ due punti di un reticolo temporale con passo $a=1$ e composto di $N$ elementi (nel nostro caso, $N=64$).
Utilizzando la teoria del \emph{path integral} di Feynman, sappiamo che il correlatore è definito come
$$ \left<x_{i_1},x_{i_2}\right> = \frac{1}{Z}\int\prod_{i=0}^{N-1}dx_i\,e^{-S}x_{i_1}x_{i_2} $$
con $S$ funzionale dell'azione:
$$ S = a\sum_{i=0}^{N-1} \left[ \frac{m}{2} \left( \frac{x_{i+1}-x_i}{a} \right)^2+V(x_i)\right]$$

Calcoliamo i correlatori utilizzando una catena di Markov (attraverso l'algoritmo di Metropolis) per estrarre elementi con distribuzione di probabilità $e^{-S}/Z$. Ricordiamo che, dato uno stato della catena $E_j=(x_0\dots x_{N-1})$, il correlatore su quello stato è calcolabile come:
$$c_t=\frac{1}{N}\sum_{i=0}^{N-1}x_ix_{i+t}$$
dove $N$ è sempre il numero di passi reticolari.

Possiamo già calcolare il correlatore medio (ovvero il correlatore $c_t$ mediato su tutti i tempi Markoviani) e disegnarlo in funzione della distanza reticolare.

\begin{center}
 \includegraphics[scale=0.5]{../images/correlmediocorr.png}
\end{center}

Notiamo che, come ci aspettiamo, il grafico è perfettamente simmetrico.

Raffiniamo ora la nostra analisi. Possiamo migliorare il nostro algoritmo aspettando un tempo Markoviano sufficiente a far sì che la catena di Markov che abbiamo costruito con l'algoritmo del Metropolis \emph{termalizzi}, ovvero in modo tale che l'azione si stabilizzi intorno a un certo valore. Si noti che si ricerca la termalizzazione soltanto per ridurre l'errore che effettivamente commettiamo (aumentando dunque l'efficienza del nostro algoritmo). Il metodo rimane infatti valido anche considerando ogni \emph{sweep}, poiché il contributo dei primi \emph{sweep} diminuisce a ogni iterazione.
\begin{center}
 \includegraphics[scale=0.5]{../images/termalizzazione.png}
\end{center}

Per calcolare i livelli energetici correttamente, dobbiamo anche tenere conto del fatto che per calcolare il \emph{path integral} senza applicare correzioni, le variabili estratte dal nostro generatore di numeri casuali debbano essere decorrelate. Non è questo il caso se prendiamo semplicemente \emph{sweep} consecutivi delle catene di Markov, ma dobbiamo attendere un numero di sweep sufficienti.

Per valutare il tempo Markoviano necessario alla decorrelazione degli stati, consideriamo la funzione di autocorrelazione
$$\Gamma(t) = \left<a^ia^{i+t}\right>\left<a\right>^2$$
dove $a$ è il nostro osservabile ($a=x_ix_j$) e $t$ è il tempo Markoviano.

L'andamento di $\Gamma(t)$ è esponenziale, eseguiamo dunque un fit per valutare il tempo entro il quale possiamo assumere le variabili come decorrelate. Il grafico ottenuto è normalizzato in quanto ogni quantità è stata divisa per $\Gamma(0)$.

\begin{center}
 \includegraphics[scale=0.5]{../images/autocorr.png}
\end{center}

Il fit mostra che il tempo di autocorrelazione $\tau$ è circa pari a 30 sweep, da cui consideriamo gruppi di correlatori da 100 sweep. Per ognuno di questi gruppi calcoliamo il correlatore medio come sopra, e ricaviamo l'errore utilizzando i cluster Jacknife.

\begin{center}
 \includegraphics[scale=0.5]{../images/correlmedio.png}
\end{center}

Possiamo calcolare a questo punto il valore $\Delta E=E_1-E_0$. Calcoliamo soltanto i primi 4 elementi in quanto con il metodo utilizzato l'errore cresce esponenzialmente all'aumentare della distanza reticolare:

$$\frac{\text{Var}(x_k, x_l)}{\left<x_k x_l\right>^2} \sim e^{\Delta E}$$

\begin{center}
\begin{tabular}{c|c|c}
\hline
Distanza reticolare & $\Delta E$ & $\sigma$ \\
\hline
1 & 0.966 & 0.019\\
2&0.949&0.033 \\
3&0.827 &0.107 \\
4&1.391 &0.235 \\
\hline
\end{tabular}
\end{center}

Notiamo che i risultati ottenuti si discostano da quelli che avremmo potuto ottenere risolvendo direttamente autovalori ed autovettodi dell'Hamiltoniana. La ragione di questo fatto consta principalmente nel fatto che i due risultati saranno equivalenti nel limite dei passi del reticolo $N\to\infty$ e $a\to0$.


\section{Calcolo di equazioni differenziali}

La risoluzione numerica di equazioni differenziali è un problema molto comune in fisica. Il primo metodo che analizzeremo per risolvere queste equazioni fu sviluppato da Eulero, e si basa sulla definizione di derivata.

Supponiamo infatti di avere un classico problema di Cauchy:
$$
\begin{cases}
&\dot{x}(t)=f(x(t)) \\
&x(t_0) = x_0
\end{cases}
$$

Il metodo di Eulero non è altro che il troncamento al primo ordine della definizione:

$$\dot{x} = \frac{x(t + \Delta t)-x(t)}{\Delta t} + o(\Delta t^2)$$

Dunque conoscendo le condizioni iniziali, si fissa $\Delta t$ e si calcolano iterativamente le soluzioni per ogni passo.

Il metodo di Eulero è però un metodo poco efficiente e molto impreciso, essendo solo del primo ordine. L'algoritmo di Runge-Kutta al quart'ordine è un raffinamento che cerca di migliorare la valutazione dell'incremento della funzione, utilizzando ulteriori punti di campionamento ed utilizzando derivate di ordine successivo.

Per semplicità, consideriamo prima il metodo di Runge-Kutta del secondo ordine e sviluppiamo secondo Taylor la soluzione nei punti $t_n$ e $t_{n+1}$, centrando lo sviluppo nel punto intermedio. Procedendo in questo modo otteniamo una formula precisa fino al terzo ordine:

$$ x(t_{n+1}) = x(t_n) + f(x(t_{n+1/2}), t_{n+1/2})h + o(h^3)$$

Siccome poi $f(x(t_{n+1/2}), t_{n+1/2})$ ha un termine in $h$, è possibile calcolare $x(t_{n+1/2})$ con il metodo di Eulero e mantenere la precisione voluta al terzo ordine.

L'estensione al quarto ordine è analoga. Scriviamo nuovamente l'espansione in serie, questa volta fino al quarto ordine
$$ x_{n+1} = x_n + ak_1 + bk_2 + ck_3 + dk_4$$
dove i coefficienti

$$\begin{array}{rl}
k_1 &:= hf(x_n, t_n) \\
k_2 &:= hf(x_n + \frac{1}{2}k_1, t_{n+1/2}) \\
k_3 &:= hf(x_n + \frac{1}{2}k_2, t_{n+1/2}) \\
k_4 &:= hf(x_n + k_3, t_{n+1}) \\
\end{array}$$

Scegliamo i coefficienti in maniera opportuna ed arriviamo alla formula di Runge-Kutta del quarto ordine per il punto $t_{n+1}$

$$x(t_{n+1}) = x(t_n) + \frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4)$$

\subsection{Il pendolo forzato-smorzato}

Utilizziamo i metodi di integrazione numerica di Runge-Kutta per risolvere alcuni esempi fisici. Studieremo in particolare il caso di un pendolo sottoposto ad attrito, forza peso e una forzante.

Un pendolo semplice di braccio $R$ è descritto dalla classica equazione
$$\ddot{\theta} = -\frac{g}{R}\sin(\theta)$$
a cui va aggiunto il termine di attrito e il termine forzante. La nostra equazione diventa così
$$\ddot{\theta} = -\frac{g}{R}\sin(\theta) -\frac{k}{m}\dot{\theta} + \frac{f}{mR}\cos(\omega t) $$

Riduciamo l'equazione del secondo ordine ad un sistema di equazioni differenziali del primo ordine mediante il cambio di variabili

$$
\begin{cases}{rl}
\dot{x_1}&=x_2 \\
\dot{x_2}&=-\sin(x_1) - qx_2 +b\cos(\omega t)
\end{cases}
$$

dove $q$ e $b$ rappresentano i coefficienti numerici ricavabili dalla precedente equazione.

Poniamo come condizioni iniziali $x_1 = \pi/6$ e $x_2 = 0$ (pendolo fermo) e studiamo l'evoluzione nel piano delle fasi per diversi valori di $b$ e di $q$.

\end{document}